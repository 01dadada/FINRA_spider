import argparse
import time

import pandas as pd
import requests
from dotenv import load_dotenv
from requests.exceptions import RequestException

load_dotenv()

import os

TOKEN_URL = os.getenv("TOKEN_URL", "https://ews.fip.finra.org/fip/rest/ews/oauth2/access_token")
BASE_URL = os.getenv("BASE_URL", "https://api.finra.org/data/group/OTCMarket/name/")
LIMIT = int(os.getenv("limit", "5000"))
RETRY_DELAY_SECONDS = int(os.getenv("retry_delay_seconds", "60"))
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "10"))
TOKEN_REFRESH_INTERVAL = int(os.getenv("TOKEN_REFRESH_INTERVAL", "300"))
USERNAME = os.getenv("USERNAME")
PASSWORD = os.getenv("PASSWORD")
DATASET = os.getenv("DATASET", "monthlySummary")
DEFAULT_SAVE_FOLDER = os.getenv("SAVE_FOLDER", "data_output")


def main():
    all_data = []
    file_counter = 1
    REQUEST_SAVE_INTERVAL = 200  # æ¯200æ¬¡ä¿å­˜ä¸€ä¸ªç‹¬ç«‹æ–‡ä»¶

    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", required=True, help="è¦è·å–çš„æ•°æ®é›†åç§°", default="monthlySummary")
    parser.add_argument("--limit", required=False, help="æ¯æ¬¡è¯·æ±‚çš„æ•°æ®é‡é™åˆ¶", default=LIMIT)
    parser.add_argument(
        "--retry_delay_seconds", required=False, help="é€Ÿç‡é™åˆ¶åçš„é‡è¯•ç­‰å¾…æ—¶é—´", default=RETRY_DELAY_SECONDS
    )
    parser.add_argument("--max_retries", required=False, help="ç½‘ç»œé”™è¯¯çš„é‡è¯•æ¬¡æ•°", default=MAX_RETRIES)
    parser.add_argument(
        "--token_refresh_interval", required=False, help="Token åˆ·æ–°é—´éš”", default=TOKEN_REFRESH_INTERVAL
    )
    parser.add_argument("--username", required=False, help="ç”¨æˆ·å", default=USERNAME)
    parser.add_argument("--password", required=False, help="å¯†ç ", default=PASSWORD)
    parser.add_argument("--offset", required=False, help="èµ·å§‹ä½ç½®", default=0)
    parser.add_argument("--save_folder", required=True, help="ä¿å­˜ç›®æ ‡æ–‡ä»¶å¤¹", default=DEFAULT_SAVE_FOLDER)
    args = parser.parse_args()

    dataset = args.dataset
    limit = int(args.limit)
    retry_delay_seconds = int(args.retry_delay_seconds)
    max_retries = int(args.max_retries)
    token_refresh_interval = int(args.token_refresh_interval)
    username = args.username
    password = args.password
    file_base_name = dataset
    offset = int(args.offset)
    save_folder = args.save_folder

    # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(save_folder, exist_ok=True)

    def get_access_token():
        TOKEN_PAYLOAD = {
            "grant_type": "client_credentials",
            "apiclientid": username,
            "apiclientsecret": password,
        }
        token_headers = {"Accept": "application/json", "Content-Type": "application/json"}

        print("--- ğŸ”„ æ­£åœ¨è¯·æ±‚æ–°çš„ Access Token ---")

        for attempt in range(max_retries):
            try:
                response = requests.post(TOKEN_URL, auth=(username, password), data=TOKEN_PAYLOAD, timeout=30)
                response.raise_for_status()
                token_data = response.json()
                access_token = token_data.get("access_token")

                if access_token:
                    print("--- âœ… Access Token è·å–æˆåŠŸ ---")
                    return access_token, time.time()
                else:
                    print(f"--- âŒ Token å“åº”ä¸­ç¼ºå°‘ 'access_token' å­—æ®µ: {token_data} ---")
                    time.sleep(retry_delay_seconds)

            except RequestException as e:
                print(f"--- âš ï¸ ç½‘ç»œé”™è¯¯ï¼Œå°è¯•ç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•ï¼š{e} ---")
                time.sleep(retry_delay_seconds)

        raise RuntimeError("æ— æ³•è·å–Access Token")

    url = f"{BASE_URL}{dataset}"
    request_counter = 0
    current_access_token, token_acquisition_time = get_access_token()

    while True:
        if time.time() - token_acquisition_time > token_refresh_interval:
            try:
                current_access_token, token_acquisition_time = get_access_token()
            except Exception as e:
                print(f"--- âŒ Token æ›´æ–°å¤±è´¥ï¼Œè·³è¿‡ {dataset}ï¼š{e} ---")
                break  # è·³è¿‡å½“å‰æ•°æ®é›†
        data_headers = {"accept": "application/json", "Authorization": f"Bearer {current_access_token}"}
        param = {
            "limit": limit,
            "offset": offset,
        }
        print(f"  â¡ï¸ è¯·æ±‚ {dataset} offset: {offset}")
        try:
            response = requests.get(url, headers=data_headers, params=param, timeout=60)
            response.raise_for_status()
            data = response.json()
            count = len(data)
            all_data.extend(data)
            print(f"  âœ… æˆåŠŸè·å– {count} æ¡è®°å½•ã€‚æ€»è®¡: {len(all_data)}")
            # å¦‚æœè¿”å›çš„è®°å½•æ•°å°‘äº limitï¼Œè¯´æ˜å·²æ˜¯æœ€åä¸€é¡µ
            offset += limit
            request_counter += 1

            if request_counter % REQUEST_SAVE_INTERVAL == 0:
                df = pd.DataFrame(all_data)
                filename = os.path.join(save_folder, f"{file_base_name}_part{file_counter}.csv")
                df.to_csv(filename, sep="|", index=False, encoding="utf-8")
                print(f"--- æ–‡ä»¶ä¿å­˜æˆåŠŸ: {filename} ---")
                all_data = []
                file_counter += 1

            if count < limit:
                print(f"--- ğŸ‰ {dataset} æ•°æ®è·å–å®Œæˆï¼Œæœ€åä¸€æ‰¹æ•°æ®å³å°†ä¿å­˜ï¼Œæ€»å…±è¯·æ±‚æ¬¡æ•°: {request_counter} ---")
                break
        except RequestException as e:
            print(f"--- âŒ æ•°æ®è¯·æ±‚å‘ç”Ÿé”™è¯¯ï¼š{e} ---")
            print(f"--- âš ï¸ å°è¯•ç­‰å¾… {retry_delay_seconds} ç§’åé‡è¯•... ---")
            # ä¿å­˜ä¸´æ—¶æ•°æ®ä¸ºæ–°åˆ†ç‰‡
            if all_data:
                df = pd.DataFrame(all_data)
                filename = os.path.join(save_folder, f"{file_base_name}_part{file_counter}.csv")
                df.to_csv(filename, sep="|", index=False, encoding="utf-8")
                print(f"--- ä¸´æ—¶æ•°æ®å·²ä¿å­˜: {filename} ---")
            time.sleep(retry_delay_seconds)
        except Exception as e:
            print(f"--- âŒ å‘ç”Ÿæ„å¤–é”™è¯¯ï¼š{e} ---")
            if all_data:
                df = pd.DataFrame(all_data)
                filename = os.path.join(save_folder, f"{file_base_name}_part{file_counter}.csv")
                df.to_csv(filename, sep="|", index=False, encoding="utf-8")
                print(f"--- ä¸´æ—¶æ•°æ®å·²ä¿å­˜: {filename} ---")
            raise e
    # æ£€æŸ¥æ˜¯å¦æœ‰å‰©ä½™æœªä¿å­˜çš„æ•°æ®
    if all_data:
        df = pd.DataFrame(all_data)
        filename = os.path.join(save_folder, f"{file_base_name}_part{file_counter}.csv")
        df.to_csv(filename, sep="|", index=False, encoding="utf-8")
        print(f"--- æ–‡ä»¶ä¿å­˜æˆåŠŸ: {filename} ---")


if __name__ == "__main__":
    main()
